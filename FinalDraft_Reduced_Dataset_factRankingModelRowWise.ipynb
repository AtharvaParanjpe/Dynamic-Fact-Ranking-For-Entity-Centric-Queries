{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalDraft Reduced Dataset factRankingModelRowWise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "slCrtu6DptEj",
        "colab_type": "code",
        "outputId": "089a74db-aeb2-4979-84e1-41b289140b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install keras\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "# !pip install -q pyyaml h5py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "from keras.layers import LSTM, GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Bidirectional\n",
        "from keras.layers import concatenate,Dropout"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 63.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (46.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm5Pw8lRrdF_",
        "colab_type": "code",
        "outputId": "4e7d946a-2ce1-48cc-aa88-dac0c4fe66b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-48b_J8Djeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel2(tf.keras.Model):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(MyModel2, self).__init__()\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=(512),embeddings_initializer=\"glorot_normal\")\n",
        "        self.bidirectional_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True))\n",
        "        self.dense_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    def __call__(self, q, p, o):\n",
        "\n",
        "        ## embedding layer\n",
        "        queryEmbedding = self.embedding_layer(q)\n",
        "        predEmbedding = self.embedding_layer(p)\n",
        "        objEmbedding = self.embedding_layer(o)        \n",
        "\n",
        "        ## reshaping before feeding to Bi-LSTM\n",
        "        queryEmbedding = tf.reshape(queryEmbedding, (1, queryEmbedding.shape[0], queryEmbedding.shape[1]))\n",
        "        predEmbedding = tf.reshape(predEmbedding, (1, predEmbedding.shape[0], predEmbedding.shape[1]))\n",
        "        objEmbedding = tf.reshape(objEmbedding, (1, objEmbedding.shape[0], objEmbedding.shape[1]))\n",
        "        \n",
        "        ## Bi-LSTM\n",
        "        queryEmbedding = self.bidirectional_lstm(queryEmbedding)\n",
        "        predEmbedding = self.bidirectional_lstm(predEmbedding)\n",
        "        objEmbedding = self.bidirectional_lstm(objEmbedding)\n",
        "        \n",
        "        ## taking the first and last outputs of lstm layer \n",
        "        ## first -> right context\n",
        "        ## last -> left context\n",
        "        queryConcat = tf.concat([queryEmbedding[:,0,:512],queryEmbedding[:,49,512:]],axis=1)\n",
        "        predConcat = tf.concat([predEmbedding[:,0,:512],predEmbedding[:,49,512:]],axis=1)\n",
        "        objConcat = tf.concat([objEmbedding[:,0,:512],objEmbedding[:,49,512:]],axis=1)\n",
        "        \n",
        "\n",
        "        ## (q + p).oT = target\n",
        "        customTarget = queryConcat+predConcat           \n",
        "        customTarget=tf.matmul(customTarget,tf.transpose(objConcat))\n",
        "        \n",
        "        return customTarget\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tQvFmHdRRjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## homogeneous encoding for all the queries,predicates, objects\n",
        "maxLengthPadding = 50\n",
        "\n",
        "\n",
        "## split the words in predicates and objects\n",
        "def splitCamelCasing(camelCasedWord):\n",
        "    camelCaseSplit = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', camelCasedWord)).split()\n",
        "    return camelCaseSplit\n",
        "facts = pd.read_excel('/content/drive/My Drive/Independent Study/output.xlsx')\n",
        "facts = facts.drop([\"id\", \"qid\", \"imp\", \"rel\", \"en_id\"], axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GIFg_XARqJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## To give a higher importance to a higher utility value\n",
        "def invertRanks(rankArray):\n",
        "  maximum = 5 \n",
        "  for i in range(len(rankArray)):\n",
        "    if(rankArray[i]==0):\n",
        "      rankArray[i]=1/maximum\n",
        "    else:\n",
        "      rankArray[i]=rankArray[i]/maximum\n",
        "  return rankArray\n",
        "\n",
        "\n",
        "ENCODING_DIM = 50\n",
        "maxRank = 0\n",
        "y = invertRanks(list(facts['utility'].values))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV-xh92WqapC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_dictionary = {}\n",
        "\n",
        "## Creates an encoding for the entire wordList\n",
        "def encode_sequence(wordList):\n",
        "    encodedValue = []  ## dimension of embedding\n",
        "    for word in wordList:\n",
        "        encodedValue += [embeddings_dictionary[word]]\n",
        "    ## padding the remaining values to create a homogeneous encoding\n",
        "    encodedValue += [0] * (maxLengthPadding - len(encodedValue))\n",
        "    return encodedValue\n",
        "\n",
        "\n",
        "################################################# Preparing the Embedding Space / Dictionary of Words ############################################\n",
        "\n",
        "\n",
        "############# 1. The query encoding ###############\n",
        "\n",
        "x = []\n",
        "queryWords = []\n",
        "adjustedPredicates = []\n",
        "objWords = []\n",
        "\n",
        "for i in range(len(facts[\"pred\"])):\n",
        "    ## splitting the query\n",
        "    tempName = re.sub('[^a-zA-Z0-9 \\n\\.]', '', facts[\"query\"].values[i].strip())\n",
        "    queryWords += tempName.lower().strip().split(\" \")\n",
        "\n",
        "    ## splitting the object\n",
        "    oW = facts[\"obj\"].values[i].lower().strip()\n",
        "    if ('<' in oW and '>' in oW and 'dbp' in oW):\n",
        "        oW = oW.split(\":\")\n",
        "        oW = oW[1].split(\">\")\n",
        "        oW = oW[0].split('_')\n",
        "    elif ('www' in oW):\n",
        "        oW = oW.split(\".\")\n",
        "    else:\n",
        "        oW = oW.split(\" \")\n",
        "\n",
        "    ## for removing special characters\n",
        "    oW = [re.sub('[^a-zA-Z0-9 \\n\\.]', '', x) for x in oW]\n",
        "    objWords += oW\n",
        "    \n",
        "    #splitting the predicates\n",
        "    pred = facts[\"pred\"].values[i].lower().split(\":\")\n",
        "    pred = pred[1].split(\">\")\n",
        "    pred = splitCamelCasing(pred[0])\n",
        "    pred = [re.sub('[^a-zA-Z0-9 \\n\\.]', '', x) for x in pred]\n",
        "    adjustedPredicates += pred\n",
        "\n",
        "totalWords = queryWords + adjustedPredicates + objWords\n",
        "totalWords = set(totalWords)\n",
        "vocab_size = len(totalWords)\n",
        "\n",
        "## creating the dictionary\n",
        "for i, x in enumerate(totalWords):\n",
        "    embeddings_dictionary[x] = i\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wocCFARiYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queryWordEncodings = []\n",
        "predWordEncodings = []\n",
        "objWordEncodings = []\n",
        "\n",
        "\n",
        "for i in range(len(facts[\"pred\"].values)):\n",
        "\n",
        "    name = re.sub('[^a-zA-Z0-9 \\n\\.]', '', facts[\"query\"].values[i])\n",
        "    queryWords = name.lower().strip().split(\" \")\n",
        "    queryWordEncodings += [encode_sequence(queryWords)]\n",
        "    \n",
        "    ## similar to creating the dictionary, but this time it encodes the words using the values from dictionary\n",
        "    oW = facts[\"obj\"].values[i].lower().strip()\n",
        "    if ('<' in oW and '>' in oW and 'dbp' in oW):\n",
        "        oW = oW.split(\":\")\n",
        "        oW = oW[1].split(\">\")\n",
        "        oW = oW[0].split('_')\n",
        "    elif ('www' in oW):\n",
        "        oW = oW.split(\".\")\n",
        "    else:\n",
        "        oW = oW.split(\" \")\n",
        "\n",
        "    ## for removing special characters\n",
        "    oW = [re.sub('[^a-zA-Z0-9 \\n\\.]', '', x) for x in oW]\n",
        "    oW = encode_sequence(oW)\n",
        "    objWordEncodings += [oW]\n",
        "\n",
        "    ## encoding the words of predicates\n",
        "    pred = facts[\"pred\"].values[i].lower().split(\":\")\n",
        "    pred = pred[1].split(\">\")\n",
        "    pred = splitCamelCasing(pred[0])\n",
        "    pred = [re.sub('[^a-zA-Z0-9 \\n\\.]', '', x) for x in pred]\n",
        "    predWordEncodings += [encode_sequence(pred)]\n",
        "\n",
        "# print(len(queryWordEncodings[0]),len(objWordEncodings[0]),len(predWordEncodings[0]))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3plOo820z0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## defining custom model parameters as per tensorflow2 guidelines\n",
        "\n",
        "model_2 = MyModel2(vocab_size)\n",
        "loss_obj = tf.keras.losses.MeanSquaredError()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.MeanSquaredError(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.MeanSquaredError(name='test_accuracy')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIdv_M87dRwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## x_tr : training x -> contains the query data, predicate data, object data\n",
        "## y_tr : training y -> contains the normalized targets\n",
        "def train_step(x_tr,y_tr):\n",
        "    qE = x_tr[0]\n",
        "    pE = x_tr[1]\n",
        "    oE = x_tr[2]\n",
        "    batch_loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        for i in range(len(qE)):\n",
        "            q= tf.convert_to_tensor(qE[i], dtype=tf.int32)\n",
        "            p = tf.convert_to_tensor(pE[i], dtype=tf.int32)\n",
        "            o = tf.convert_to_tensor(oE[i], dtype=tf.int32)\n",
        "            predictions = model_2(q, p, o)\n",
        "            loss = loss_obj(y_tr[i],predictions)\n",
        "            batch_loss+=loss\n",
        "        gradients = tape.gradient(batch_loss/len(qE), model_2.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model_2.trainable_variables))\n",
        "    return batch_loss\n",
        "  \n",
        "  \n",
        "## test data set\n",
        "def test_step(x_ts,y_ts):\n",
        "    queryWordEncodings = x_ts[0]\n",
        "    predWordEncodings = x_ts[1]\n",
        "    objWordEncodings = x_ts[2]\n",
        "    loss_mean_test = 0\n",
        "    # print(\"--------------------------------------------------------x--------------------------------------------------------x-----------------------------------------------\")  \n",
        "    for i in range(len(queryWordEncodings)):\n",
        "        q= tf.convert_to_tensor(queryWordEncodings[i], dtype=tf.int32)\n",
        "        p = tf.convert_to_tensor(predWordEncodings[i], dtype=tf.int32)\n",
        "        o = tf.convert_to_tensor(objWordEncodings[i], dtype=tf.int32)\n",
        "        predictions = model_2(q,p,o)\n",
        "        t_loss = loss_obj(y_ts[i], predictions)\n",
        "        loss_mean_test+=t_loss\n",
        "        test_loss(t_loss)\n",
        "        test_accuracy(y_test[i], predictions)\n",
        "        # print(i)\n",
        "    return loss_mean_test/len(queryWordEncodings)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUsDyeeWiXo3",
        "colab_type": "code",
        "outputId": "2ae3b9bb-f9fb-41eb-90df-fdbabb74d8c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "data_len = len(queryWordEncodings)\n",
        "\n",
        "queryWordEncodingsTrain,predWordEncodingsTrain,objWordEncodingsTrain,y_train = shuffle(queryWordEncodings[:data_len],objWordEncodings[:data_len],predWordEncodings[:data_len],y[:data_len])\n",
        "queryWordEncodingsTest,predWordEncodingsTest,objWordEncodingsTest,y_test = shuffle(queryWordEncodings[data_len:],objWordEncodings[data_len:],predWordEncodings[data_len:],y[data_len:])\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "num_batches_train = math.floor(data_len/batch_size)\n",
        "\n",
        "test_size = len(queryWordEncodings)\n",
        "num_batches_test = math.floor(test_size/batch_size)\n",
        "\n",
        "\n",
        "print(\"Num Batches Train:\",num_batches_train)\n",
        "print(data_len/batch_size)\n",
        "print(len(y_train))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Batches Train: 81\n",
            "81.8125\n",
            "1309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcF6r-mNauYz",
        "colab_type": "code",
        "outputId": "96853929-a1fb-4648-e3d4-5f822e7e2f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  loss_per_epoch = 0\n",
        "\n",
        "  for i in range(num_batches_train):\n",
        "    x_train = [queryWordEncodingsTrain[i*batch_size:(i+1)*batch_size],predWordEncodingsTrain[i*batch_size:(i+1)*batch_size],objWordEncodingsTrain[i*batch_size:(i+1)*batch_size]]\n",
        "    loss1 = train_step(x_train,y_train[i*batch_size:(i+1)*batch_size])\n",
        "    loss_per_epoch += loss1\n",
        "  x_train = [queryWordEncodingsTrain[num_batches_train*batch_size:],predWordEncodingsTrain[num_batches_train*batch_size:],objWordEncodingsTrain[num_batches_train*batch_size:]]\n",
        "  loss1 = train_step(x_train,y_train[num_batches_train*batch_size:])\n",
        "  loss_per_epoch += loss1\n",
        "  print(\"Epoch Loss for epoch \"+str(epoch)+\": \",loss_per_epoch/(num_batches_train+1) )\n",
        "\n",
        "  # for i in range(num_batches_test):\n",
        "  #   x_test = [queryWordEncodingsTest[i*batch_size:(i+1)*batch_size],predWordEncodingsTest[i*batch_size:(i+1)*batch_size],objWordEncodingsTest[i*batch_size:(i+1)*batch_size]]\n",
        "  #   loss2 = test_step(x_test,y_test[i*batch_size:(i+1)*batch_size])\n",
        "  #   print(loss2)  \n",
        "\n",
        "  # x_test = [queryWordEncodingsTest[num_batches_test*batch_size:],predWordEncodingsTest[num_batches_test*batch_size:],objWordEncodingsTest[num_batches_test*batch_size:]]\n",
        "  # loss2 = test_step(x_test,y_test[num_batches_test*batch_size:])\n",
        "  # print(loss2)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch Loss for epoch 0:  tf.Tensor(0.4818991, shape=(), dtype=float32)\n",
            "Epoch Loss for epoch 1:  tf.Tensor(0.23604867, shape=(), dtype=float32)\n",
            "Epoch Loss for epoch 2:  tf.Tensor(0.13714768, shape=(), dtype=float32)\n",
            "Epoch Loss for epoch 3:  tf.Tensor(0.11405318, shape=(), dtype=float32)\n",
            "Epoch Loss for epoch 4:  tf.Tensor(0.18292435, shape=(), dtype=float32)\n",
            "Epoch Loss for epoch 5:  tf.Tensor(0.19767022, shape=(), dtype=float32)\n",
            "Epoch Loss for epoch 6:  tf.Tensor(0.14313562, shape=(), dtype=float32)\n",
            "Epoch Loss for epoch 7:  tf.Tensor(0.07201068, shape=(), dtype=float32)\n",
            "Epoch Loss for epoch 8:  tf.Tensor(0.0597663, shape=(), dtype=float32)\n",
            "Epoch Loss for epoch 9:  tf.Tensor(0.05771786, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETUejsMdbRpX",
        "colab_type": "code",
        "outputId": "ef7984b9-7aee-489b-a345-1ea6e38800a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_2.save_weights('/content/drive/My Drive/Independent Study/MiniBatch_URI_Data')\n",
        "\n",
        "model_load = MyModel2(vocab_size)\n",
        "model_load.load_weights('/content/drive/My Drive/Independent Study/MiniBatch_URI_Data')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8eb21f7550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW5-9wsnm_7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## grouping the dataset by query to get the ndcg scores\n",
        "\n",
        "def modifiedInvertRanks(rankArray):\n",
        "  for rank in rankArray:\n",
        "    maximum = 5 \n",
        "    for j in range(len(rank)):\n",
        "      if(rank[j]==0):\n",
        "        rank[j]=1/maximum\n",
        "      else:\n",
        "        rank[j]=rank[j]/maximum\n",
        "    \n",
        "  return rankArray\n",
        "\n",
        "modified_y = []\n",
        "groupedResults = facts.groupby('query')\n",
        "\n",
        "for name, group in groupedResults:\n",
        "    g = list(group['utility'].values)\n",
        "    # print(len(g))\n",
        "    modified_y.append(g)\n",
        "modified_y = modifiedInvertRanks(modified_y)\n",
        "\n",
        "\n",
        "queryWordEncodings = []\n",
        "predWordEncodings = []\n",
        "objWordEncodings = []\n",
        "\n",
        "predictedQueryRanks = []\n",
        "groundTruthRanks = []\n",
        "\n",
        "count = 0\n",
        "\n",
        "for query, group in groupedResults:\n",
        "\n",
        "    ## name is the query used for grouping\n",
        "    query = re.sub('[^a-zA-Z0-9 \\n\\.]', '', query)\n",
        "    queryWords = query.lower().strip().split(\" \")\n",
        "    q = encode_sequence(queryWords)\n",
        "    predictedRanksPerQuery = []\n",
        "    groundTruthRanksPerQuery = []\n",
        "\n",
        "    ## encoding predicate-objects\n",
        "    \n",
        "    for i in range(len(group[\"obj\"].values)):\n",
        "        oW = group[\"obj\"].values[i].lower().strip()\n",
        "        if ('<' in oW and '>' in oW and 'dbp' in oW):\n",
        "            oW = oW.split(\":\")\n",
        "            oW = oW[1].split(\">\")\n",
        "            oW = oW[0].split('_')\n",
        "        elif ('www' in oW):\n",
        "            oW = oW.split(\".\")\n",
        "        else:\n",
        "            oW = oW.split(\" \")\n",
        "\n",
        "        ## for removing special characters\n",
        "        oW = [re.sub('[^a-zA-Z0-9 \\n\\.]', '', x) for x in oW]\n",
        "        o = encode_sequence(oW)\n",
        "        \n",
        "        pred = group[\"pred\"].values[i].lower().split(\":\")\n",
        "        pred = pred[1].split(\">\")\n",
        "        pred = splitCamelCasing(pred[0])\n",
        "        pred = [re.sub('[^a-zA-Z0-9 \\n\\.]', '', x) for x in pred]\n",
        "        p = encode_sequence(pred)\n",
        "        \n",
        "        q= tf.convert_to_tensor(q, dtype=tf.int32)\n",
        "        p = tf.convert_to_tensor(p, dtype=tf.int32)\n",
        "        o = tf.convert_to_tensor(o, dtype=tf.int32)\n",
        "        \n",
        "        predictions = model_load(q, p, o)\n",
        "        predictedRanksPerQuery.append(tf.math.round(predictions*5).numpy().tolist()[0][0])\n",
        "\n",
        "    g_t = [x*5 for x in modified_y[count]]\n",
        "    groundTruthRanks.append(g_t)\n",
        "    predictedQueryRanks.append(predictedRanksPerQuery)\n",
        "    count+=1\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5J_MeOUH9Jg",
        "colab_type": "code",
        "outputId": "7a7812be-07c1-40d2-8481-f35a40227c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "def dcg_score(y_true, y_score, k=5):\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "    gain = 2 ** y_true - 1\n",
        "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
        "    return np.sum(gain / discounts)\n",
        "\n",
        "\n",
        "def ndcg_score(ground_truth, predictions, k=5):\n",
        "    scores = []\n",
        "    for y_true, y_score in zip(ground_truth, predictions):\n",
        "        actual = dcg_score(y_true, y_score, k)\n",
        "        best = dcg_score(y_true, y_true, k)\n",
        "        score = float(actual) / float(best)\n",
        "        scores.append(score)\n",
        "\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "print(\"NDCG@5:\",ndcg_score(groundTruthRanks,predictedQueryRanks,k=5))\n",
        "print(\"NDCG@10:\",ndcg_score(groundTruthRanks,predictedQueryRanks,k=10))\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NDCG@5: 0.9544463768893355\n",
            "NDCG@10: 0.9681096628514892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10crKSX3japK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fd318ed-e65c-4b49-99b7-19e51257d4a2"
      },
      "source": [
        "## to check the embedding space\n",
        "\n",
        "for x in embeddings_dictionary.keys():\n",
        "  print(x)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tacky\n",
            "repteam\n",
            "ostermundigen\n",
            "great\n",
            "operant\n",
            "give\n",
            "cornwall\n",
            "mediagroup\n",
            "districts\n",
            "hubairport\n",
            "elia\n",
            "klerk\n",
            "firstholder\n",
            "a.\n",
            "dont\n",
            "claudio\n",
            "elijah\n",
            "americans\n",
            "mnage\n",
            "greg\n",
            "firstminister\n",
            "kentucky\n",
            "spouse\n",
            "hooligans\n",
            "rugby\n",
            "bulgaria\n",
            "football\n",
            "nationalanthem\n",
            "oklahoma\n",
            "methodism\n",
            "anchorage\n",
            "iso\n",
            "donlan\n",
            "computer\n",
            "presbyterian\n",
            "outer\n",
            "3\n",
            "ohio\n",
            "manufacturing\n",
            "v\n",
            "album\n",
            "thomas\n",
            "nudisco\n",
            "youth\n",
            "governingbody\n",
            "libre\n",
            "philippines\n",
            "world\n",
            "metropolitan\n",
            "geotld\n",
            "commissioner\n",
            "center\n",
            "illinois\n",
            "bremen\n",
            "ammonium\n",
            "salsa\n",
            "affairs\n",
            "occupation\n",
            "canadian\n",
            "tokyo\n",
            "mandela\n",
            "governor\n",
            "kalmar\n",
            "stands\n",
            "loeb\n",
            "precedence\n",
            "mp3\n",
            "krone\n",
            "durango\n",
            "inuvialuktun\n",
            "deathplace\n",
            "germany\n",
            "german\n",
            "jimmy.\n",
            "minnesota\n",
            "climber\n",
            "legaljuris\n",
            "sri\n",
            "places\n",
            "berlin\n",
            "nicks\n",
            "nature\n",
            "baby\n",
            "pop\n",
            "eloan\n",
            "western\n",
            "anthem\n",
            "eastern\n",
            "spanish\n",
            "andress\n",
            "pacific\n",
            "cecil\n",
            "european\n",
            "hubs\n",
            "sports\n",
            "palmetto\n",
            "brimson\n",
            "yupik\n",
            "heart\n",
            "journalist\n",
            "guarantee\n",
            "travel\n",
            "debutleague\n",
            "greater\n",
            "gyude\n",
            "or\n",
            "ashley\n",
            "politician\n",
            "blankinfo\n",
            "environment\n",
            "accreditation\n",
            "carl\n",
            "house\n",
            "ringtone\n",
            "mills\n",
            "teentoday.co.uk\n",
            "u.s.\n",
            "espresso\n",
            "influenced\n",
            "start\n",
            "gwichin\n",
            "vietnam\n",
            "milton\n",
            "romanova\n",
            "cougars\n",
            "my\n",
            "basic\n",
            "innings\n",
            "cemetery\n",
            "juneau\n",
            "music\n",
            "olubanke\n",
            "is\n",
            "cyprus\n",
            "mayor\n",
            "party\n",
            "society\n",
            "2010\n",
            "eskimoaleut\n",
            "franz\n",
            "valley\n",
            "singing\n",
            "albums\n",
            "locatedinarea\n",
            "postal\n",
            "funen\n",
            "british\n",
            "prizes\n",
            "wild\n",
            "basincountries\n",
            "with\n",
            "developed\n",
            "clements\n",
            "iowa\n",
            "lucas\n",
            "president\n",
            "turtle\n",
            "karman\n",
            "4\n",
            "08\n",
            "database\n",
            "king\n",
            "indonesian\n",
            "crabb\n",
            "guido\n",
            "starring\n",
            "and\n",
            "visited\n",
            "melbourne\n",
            "wowereit\n",
            "alexander\n",
            "terminusb\n",
            "restingplace\n",
            "rossford\n",
            "media\n",
            "sylvia\n",
            "otley\n",
            "chartered\n",
            "tpfer\n",
            "deathcause\n",
            "author\n",
            "thorndike\n",
            "priscilla\n",
            "benigno\n",
            "programminglanguage\n",
            "information\n",
            "manila\n",
            "virginia\n",
            "lenny\n",
            "anonymous\n",
            "madikizelamandela\n",
            "tennis\n",
            "hamburg\n",
            "institute\n",
            "soul\n",
            "format\n",
            "alcastar\n",
            "red\n",
            "termperiod\n",
            "flowering\n",
            "trittin\n",
            "bagong\n",
            "you\n",
            "hits\n",
            "highclere\n",
            "earl\n",
            "war\n",
            "malappuram\n",
            "sabal\n",
            "scotland\n",
            "unit\n",
            "authors\n",
            "1945\n",
            "xojo\n",
            "credit\n",
            "barcelona\n",
            "name\n",
            "white\n",
            "studio\n",
            "routeend\n",
            "police\n",
            "1980\n",
            "representativetitle\n",
            "suffix\n",
            "overviewbody\n",
            "dancepop\n",
            "night\n",
            "otherparty\n",
            "inuinnaqtun\n",
            "field\n",
            "baroque\n",
            "mattress\n",
            "musicalartist\n",
            "tanzania\n",
            "formerchoreographer\n",
            "joichiro\n",
            "politics\n",
            "awit\n",
            "winning\n",
            "alternative\n",
            "citykingdoms\n",
            "qunu\n",
            "niagara\n",
            "captains\n",
            "awakening\n",
            "bhutan\n",
            "may\n",
            "romanesque\n",
            "starfleet\n",
            "quebec\n",
            "synthesizer\n",
            "fossil\n",
            "programming\n",
            "toledo\n",
            "love\n",
            "sovereign\n",
            "formertraininglocations\n",
            "contain\n",
            "argentine\n",
            "unrankedclassis\n",
            "associatedband\n",
            "mammal\n",
            "source\n",
            "bob\n",
            "angel\n",
            "through\n",
            "stun\n",
            "carrier\n",
            "unittype\n",
            "rousseau\n",
            "hardcover\n",
            "painted\n",
            "denaina\n",
            "recordings\n",
            "after\n",
            "payada\n",
            "previouswork\n",
            "defenders\n",
            "derivatives\n",
            "someday\n",
            "evelyn\n",
            "steel\n",
            "player\n",
            "straits\n",
            "skinner\n",
            "university\n",
            "b.\n",
            "epistles\n",
            "emilio\n",
            "forest\n",
            "miami\n",
            "singleparty\n",
            "beer\n",
            "region\n",
            "corriente\n",
            "grimm\n",
            "sloan\n",
            "siberian\n",
            "kanaeva\n",
            "johnson\n",
            "cristbal\n",
            ".london\n",
            "short\n",
            "jon\n",
            "were\n",
            "subsequentwork\n",
            "visual\n",
            "mark\n",
            "authority\n",
            "officer\n",
            "amsterdam\n",
            "officiallanguage\n",
            "tsimshianic\n",
            "air\n",
            "norwegians\n",
            "franke\n",
            "georgia\n",
            "drive\n",
            "published\n",
            "need\n",
            "upper\n",
            "painting\n",
            "robin\n",
            "diplomat\n",
            "britain\n",
            "ridgely\n",
            "turkey\n",
            "grammar\n",
            "codes\n",
            "2\n",
            "devolution\n",
            "recordlabel\n",
            "schei\n",
            "compton\n",
            "los\n",
            "in\n",
            "stadium\n",
            "morning\n",
            "rev\n",
            "any\n",
            "ballpark\n",
            "argento\n",
            "dogrib\n",
            "novels\n",
            "manager\n",
            "merger\n",
            "mississippi\n",
            "winners\n",
            "750mah\n",
            "establishedtitle\n",
            "what\n",
            "advanced\n",
            "immigration\n",
            "democratic\n",
            "cliff\n",
            "india\n",
            "nicole\n",
            "sevens\n",
            "tampa\n",
            "sean\n",
            "amara\n",
            "knownfor\n",
            "angela\n",
            "bass\n",
            "diplomatic\n",
            "sisterstation\n",
            "current\n",
            "representatives\n",
            "md\n",
            "peer\n",
            "brown\n",
            "familyseat\n",
            "3.7v\n",
            "press\n",
            "denmark.\n",
            "cd\n",
            "yellowknife\n",
            "moroccandutch\n",
            "astronauts\n",
            "genre\n",
            "yilan\n",
            "carlo\n",
            "officiallanguages\n",
            "act\n",
            "hill\n",
            "kerouac\n",
            "status\n",
            "schools\n",
            "norwegian\n",
            "194564\n",
            "aliso\n",
            "beckwith\n",
            "broadcasting\n",
            "category\n",
            "contentlicense\n",
            "hanoi\n",
            "international\n",
            "hardcore\n",
            "1st\n",
            "state\n",
            "story\n",
            "kuskokwim\n",
            "natural\n",
            "formerteam\n",
            "un\n",
            "partstype\n",
            "general\n",
            "jr.\n",
            "paid\n",
            "kelly\n",
            "violin\n",
            "inhibitions\n",
            "indian\n",
            "subdivisiontype\n",
            "grenville\n",
            "steak\n",
            "ronald\n",
            "directdrive\n",
            "montavista\n",
            "acm\n",
            "hadler\n",
            "ludvig\n",
            "roach\n",
            "english\n",
            "timezone\n",
            "parentcompany\n",
            "tango\n",
            "rockin\n",
            "namgyel\n",
            "coffee\n",
            "mbeki\n",
            "druk\n",
            "60\n",
            "tuccaro\n",
            "polyphony\n",
            "potato\n",
            "denali\n",
            "parnell\n",
            "r.u.f.c.\n",
            "nuevo\n",
            "food\n",
            "assembly\n",
            "london\n",
            "kidman\n",
            "wangchuck\n",
            "cityserved\n",
            "directorgeneral\n",
            "united\n",
            "fromalbum\n",
            "iii\n",
            "printmaking\n",
            "life\n",
            "pa\n",
            "boswell\n",
            "bond\n",
            "associatedmusicalartist\n",
            "residence\n",
            "1996\n",
            "yaza\n",
            "about\n",
            "chairman\n",
            "nations\n",
            "rackets\n",
            "did\n",
            "tanya\n",
            "bering\n",
            "shozo\n",
            "african\n",
            "pilot\n",
            "turing\n",
            "khesar\n",
            "steinbrck\n",
            "technology\n",
            "ontario\n",
            "william\n",
            "novel\n",
            "carolina\n",
            "righthanded\n",
            "central\n",
            "chamber\n",
            "wren\n",
            "kevin\n",
            "estefan\n",
            "main\n",
            "murkowski\n",
            "chancellors.\n",
            "honorificsuffix\n",
            "deutscher\n",
            "fort\n",
            "pictures\n",
            "gelsemium\n",
            "written\n",
            "linguistics\n",
            "fortran\n",
            "trois\n",
            "pitcher\n",
            "nld\n",
            "shipton\n",
            "geneva\n",
            "butterfly\n",
            "unitary\n",
            "marsh\n",
            "governing\n",
            "bryant\n",
            "psychology\n",
            "williams\n",
            "odd\n",
            "ahtna\n",
            "ogg\n",
            "columbian\n",
            "pontiac\n",
            "sayeh\n",
            "9\n",
            "bethlehem\n",
            "disco\n",
            "records\n",
            "presentholder\n",
            "saint\n",
            "spruance\n",
            "midi\n",
            "rob\n",
            "trinitrotoluene\n",
            "pomerantsev\n",
            "haida\n",
            "mller\n",
            "more\n",
            "israel\n",
            "loggerhead\n",
            "listing\n",
            "sofia\n",
            "kofi\n",
            "shortdescription\n",
            "lot\n",
            "nikki\n",
            "trek\n",
            "members\n",
            "lanarkshire\n",
            "gbowee\n",
            "105\n",
            "bandoneon\n",
            "know\n",
            "brothers\n",
            "willemalexander\n",
            "southeast\n",
            "child\n",
            "alcazar\n",
            ".cymru\n",
            "makoto\n",
            "unity\n",
            "joseph\n",
            "ritmo\n",
            "astronaut\n",
            "shaelynn\n",
            "whitetailed\n",
            "gyrfalcon\n",
            "hinirang\n",
            "legend\n",
            "the\n",
            "universitystillwater\n",
            "hunnam\n",
            "lower\n",
            "rokr\n",
            "massachusetts\n",
            "headquarter\n",
            "wagner\n",
            "hara\n",
            "ottawa\n",
            "harding\n",
            "eightthousander\n",
            "baseball\n",
            "indiana\n",
            "official\n",
            "selection\n",
            "copenhagen\n",
            "history\n",
            "religion\n",
            "school\n",
            "church\n",
            "collins\n",
            "citizens\n",
            "liliales\n",
            "breakbeat\n",
            "toronto\n",
            "jersey\n",
            "arnprior\n",
            "marc\n",
            "bc50\n",
            "augustus\n",
            "cities\n",
            "allmusic\n",
            "jodorowsky\n",
            "uk\n",
            "boykin\n",
            "coconut\n",
            "dover\n",
            "cape\n",
            "alaska\n",
            "seat\n",
            "architect\n",
            "amphibian\n",
            "regionallanguages\n",
            "index\n",
            "mean\n",
            "universities\n",
            "denmarknorway\n",
            "area\n",
            "christian\n",
            "line\n",
            "39\n",
            "keyperson\n",
            "indie\n",
            "double\n",
            "lewis\n",
            "sassafras\n",
            "creator\n",
            "currency\n",
            "loretta\n",
            "language\n",
            "dormer\n",
            "beaufort\n",
            "nolte\n",
            "summer\n",
            "hills\n",
            "implementations\n",
            "8\n",
            "curaao\n",
            "consensus\n",
            "orangina\n",
            "locationcity\n",
            "tandem\n",
            "currently\n",
            "recursive\n",
            "robert\n",
            "airports\n",
            "gray\n",
            "dundas\n",
            "kingdom\n",
            "battery\n",
            "pohlmann\n",
            "finnish\n",
            "mankowitz\n",
            "giants\n",
            "flower\n",
            "inc.\n",
            "atlantic\n",
            "watson\n",
            "bildungsroman\n",
            "berkeley\n",
            "harlequin\n",
            "algol\n",
            "del\n",
            "title\n",
            "annapurna\n",
            "employer\n",
            "dette\n",
            "pennsylvania\n",
            "fm\n",
            "vuelta\n",
            "generation\n",
            "george\n",
            "machel\n",
            "editing\n",
            "holikachuk\n",
            "dodgers\n",
            "radio\n",
            "aldrin\n",
            "airlines\n",
            "states\n",
            "partner\n",
            "live\n",
            "spain\n",
            "simon\n",
            "drink\n",
            "youthrepteam\n",
            "harry\n",
            "highest\n",
            "municipal\n",
            "inupiat\n",
            "sylvania\n",
            "oslo\n",
            "aviation\n",
            "of\n",
            "flowers\n",
            "posting\n",
            "constable\n",
            "terminusa\n",
            "thoreau\n",
            "susquehanna\n",
            "grand\n",
            "ocean\n",
            "butuan\n",
            "senior\n",
            "chancellor\n",
            "governmenttype\n",
            "da\n",
            "provinces\n",
            "record\n",
            "heneker\n",
            "methodist\n",
            "extend\n",
            "clarencerockland\n",
            "ginger\n",
            "collection\n",
            "schuble\n",
            "entertainment\n",
            "t100\n",
            "people\n",
            "division\n",
            "period\n",
            "niagaraonthelake\n",
            "denmark\n",
            "jrgen\n",
            "leymah\n",
            "lowe\n",
            "farnon\n",
            "saxon\n",
            "caves\n",
            "contemporary\n",
            "horst\n",
            "pilipinas\n",
            "successor\n",
            "steinmeier\n",
            "leaderparty\n",
            "huddersfield\n",
            "syms\n",
            "john\n",
            "leoni\n",
            "kazan\n",
            "herbert\n",
            "association\n",
            "parents\n",
            "blankname\n",
            "express\n",
            "nitrate\n",
            "scientist\n",
            "tor\n",
            "sauer\n",
            "owners\n",
            "galilee\n",
            "statute\n",
            "pneumonia\n",
            "ngultrum\n",
            "shine\n",
            "two\n",
            "highestpoint\n",
            "predecessor\n",
            "atari\n",
            "wilson\n",
            "bird\n",
            "building\n",
            "fairchild\n",
            "date\n",
            "lunar\n",
            "vi\n",
            "euro\n",
            "diepgen\n",
            "relative\n",
            "capital\n",
            "chukchi\n",
            "musicsubgenre\n",
            "west\n",
            "tizer\n",
            "missions\n",
            "tore\n",
            "france\n",
            "nordic\n",
            "slavey\n",
            "major\n",
            "currentclub\n",
            "trinity\n",
            "darrell\n",
            "ncc1701a\n",
            "testament\n",
            "intel\n",
            "england\n",
            "county\n",
            "queens\n",
            "machine\n",
            "monte\n",
            "independent\n",
            "adams\n",
            "releasing\n",
            "binomialauthority\n",
            "forward\n",
            "her\n",
            "locationspecial\n",
            "grove\n",
            "peso\n",
            "alex\n",
            "kintetsu\n",
            "florida\n",
            "shimbun\n",
            "georgetown\n",
            "lochaberpartieouest\n",
            "grass\n",
            "government\n",
            "tatsunori\n",
            "keep\n",
            "commission\n",
            "alaskas\n",
            "human\n",
            "skater\n",
            "waltz\n",
            "lion\n",
            "cocktail\n",
            "bohtan\n",
            "bhutanese\n",
            "business\n",
            "viceroy\n",
            "jutland\n",
            "8th\n",
            "landet\n",
            "broadcastarea\n",
            "driveson\n",
            "commonlanguages\n",
            "jews\n",
            "alaskan\n",
            "clayton\n",
            "cambridge\n",
            "honors\n",
            "yomiuri\n",
            "a\n",
            "tatsuyoshi\n",
            "governmentissued\n",
            "thommessen\n",
            "ymca\n",
            "halifax\n",
            "aquino\n",
            "leiden\n",
            "regionallanguage\n",
            "screenplay\n",
            "bernstein\n",
            "mission\n",
            "747\n",
            "surrealist\n",
            "independence\n",
            "prince\n",
            "constabulary\n",
            "federalstate\n",
            "soho\n",
            "golden\n",
            "service\n",
            "public\n",
            "thabo\n",
            "leadership\n",
            "hn\n",
            "manufacturer\n",
            "tribes\n",
            "eventstart\n",
            "constituency\n",
            "janusz\n",
            "pistol\n",
            "peerage\n",
            "reptile\n",
            "zone\n",
            "primeminister\n",
            "maryland\n",
            "f.c.\n",
            "clifton\n",
            "unsworntype\n",
            "tanacross\n",
            "constitutional\n",
            "stylisticorigins\n",
            "age\n",
            "day\n",
            "course\n",
            "lupang\n",
            "alabama\n",
            "abdulaziz\n",
            "monster\n",
            "paul\n",
            "northern\n",
            "telephone\n",
            "class\n",
            "prodigy\n",
            "located\n",
            "vice\n",
            "lilium\n",
            "surinamese\n",
            "henry\n",
            "hickshudson\n",
            "ispartof\n",
            "j.\n",
            "labels.\n",
            "liliaceae\n",
            "c\n",
            "placeofdeath\n",
            "nine\n",
            "funkytown\n",
            "maumee\n",
            "lisa\n",
            "francisco\n",
            "burnett\n",
            "affiliations\n",
            "me\n",
            "capitol\n",
            "senate\n",
            "rey\n",
            "positions\n",
            "blonde\n",
            "support\n",
            "lennon\n",
            "titledeputy\n",
            "opening\n",
            "buttle\n",
            "tawakkol\n",
            "forlani\n",
            "federalist\n",
            "counties\n",
            "stylisticorigin\n",
            "andrea\n",
            "armstrong\n",
            "girls\n",
            "operator\n",
            "last\n",
            "eventend\n",
            "monarchy\n",
            "rutte\n",
            "bluetooth\n",
            "prize\n",
            "instrument\n",
            "debutteam\n",
            "singer\n",
            "greek\n",
            "road\n",
            "holland\n",
            "designer\n",
            "heidelberg\n",
            "overseas\n",
            "elephant\n",
            "mineral\n",
            "who\n",
            "sea\n",
            "tlingit\n",
            "nadu\n",
            "konneh\n",
            "derivative\n",
            "korto\n",
            "postalcodeprefix\n",
            "1998\n",
            "patronsaint\n",
            "low\n",
            "penington\n",
            "stateanthem\n",
            "preceding\n",
            "polka\n",
            "4217\n",
            "lehigh\n",
            "ibm\n",
            "constitution\n",
            "sami\n",
            "parts\n",
            "rusevensnationalteam\n",
            "representative\n",
            "musicby\n",
            "jeanjacques\n",
            "artist\n",
            "caribbean\n",
            "realplayer\n",
            "foundation\n",
            "south\n",
            "bend\n",
            "uss\n",
            "lemonade\n",
            "accordion\n",
            "premierparty\n",
            "corporation\n",
            "tshering\n",
            "second\n",
            "1542\n",
            "catalunya\n",
            "ethnicgroups\n",
            "inventions.\n",
            "boeing\n",
            "acronym\n",
            "sirleaf\n",
            "wav\n",
            "hs850\n",
            "alutiiq\n",
            "milwaukee\n",
            "carnegie\n",
            "plymouth\n",
            "ii\n",
            "award.\n",
            "freestyle\n",
            "mclane\n",
            "alphabet\n",
            "antoinette\n",
            "scotia\n",
            "caesar\n",
            "grinnell\n",
            "arutyunyan\n",
            "elected\n",
            "blanknamesec\n",
            "countries\n",
            "timezonedst\n",
            "wulff\n",
            "quezon\n",
            "rendezvous\n",
            "beautiful\n",
            "carwyn\n",
            "lakes\n",
            "croatia\n",
            "chiyonofuji\n",
            "essex\n",
            "siblings\n",
            "laurence\n",
            "divisions\n",
            "electeetype\n",
            "subdivisionname\n",
            "liberia\n",
            "champion\n",
            "liberation\n",
            "la\n",
            "lexi\n",
            "rodney\n",
            "gnu\n",
            "bourne\n",
            "canada\n",
            "officiallang\n",
            "girl\n",
            "commodore\n",
            "kongesangen\n",
            "children\n",
            "othertopics\n",
            "roberto\n",
            "complaints\n",
            "budd\n",
            "order\n",
            "admission\n",
            "are\n",
            "glaucus\n",
            "instant\n",
            "leonard\n",
            "guitar\n",
            "eight\n",
            "power\n",
            "member\n",
            "1535\n",
            "paglikha\n",
            "burning\n",
            "christopher\n",
            "book\n",
            "borderingstates\n",
            "haley\n",
            "force\n",
            "wendy\n",
            "1888\n",
            "social\n",
            "scott\n",
            "flow\n",
            "santander\n",
            "microsd\n",
            "election\n",
            "japan\n",
            "birmingham\n",
            "papilio\n",
            "figge\n",
            "parliament\n",
            "statereligion\n",
            "powers\n",
            "tempur\n",
            "jigme\n",
            "holberg\n",
            "oregon\n",
            "street\n",
            "hamilton\n",
            "jamaica\n",
            "deer\n",
            "nagao\n",
            "lammert\n",
            "sam\n",
            "z8\n",
            "leiter\n",
            "welsh\n",
            "hal\n",
            "gulf\n",
            "mntefering\n",
            "publisher\n",
            "mvezo\n",
            "frontengine\n",
            "frisian\n",
            "belgium\n",
            "olemic\n",
            "fighter\n",
            "rock\n",
            "for\n",
            "borchiver\n",
            "toyota\n",
            "lake\n",
            "kennedy\n",
            "languagestype\n",
            "milford\n",
            "postcodes\n",
            "koyukon\n",
            "autohotkey\n",
            "province\n",
            "12\n",
            "cinematography\n",
            "nelson\n",
            "shragge\n",
            "wood\n",
            "pakistan\n",
            "electropunk\n",
            "erdman\n",
            "cameron\n",
            "realty\n",
            "sinclair\n",
            "comal\n",
            "district\n",
            "ellen\n",
            "taih\n",
            "netherlands\n",
            "semiconductor\n",
            "moon\n",
            "apollo\n",
            "ed\n",
            "religiousaffiliation\n",
            "piano\n",
            "dar\n",
            "studios\n",
            "co\n",
            "switzerland\n",
            "totaltype\n",
            "southwest\n",
            "miffy\n",
            "republic\n",
            "adam\n",
            "hansson\n",
            "freebasic\n",
            "industry\n",
            "tobgay\n",
            "schulberg\n",
            "xl\n",
            "philippine\n",
            "smoltz\n",
            "ancient\n",
            "val\n",
            "himalayan\n",
            "worth\n",
            "aires\n",
            "cola\n",
            "graham\n",
            "apartheid\n",
            "produces\n",
            "westerwelle\n",
            "fiction\n",
            "test\n",
            "iradio\n",
            "larix\n",
            "airport\n",
            "followedby\n",
            "inuktitut\n",
            "frequently\n",
            "corinthians\n",
            "irnbru\n",
            "sexual\n",
            "packet\n",
            "irina\n",
            "alliance\n",
            "e.\n",
            "kenya\n",
            "spaniel\n",
            "universal\n",
            "digital\n",
            "want\n",
            "buenos\n",
            "writerproducer\n",
            "sinner\n",
            "gilbert\n",
            "harvey\n",
            "complex\n",
            "houston\n",
            "kven\n",
            "standards\n",
            "ade\n",
            "shandy\n",
            "holiday\n",
            "guerra\n",
            "depot\n",
            "es\n",
            "weser\n",
            "f.\n",
            "italia\n",
            "league\n",
            "all\n",
            "noriega\n",
            "dryas\n",
            "conferences\n",
            "romani\n",
            "heinrich\n",
            "shawn\n",
            "memorycard\n",
            "midnight\n",
            "stay\n",
            "suchet\n",
            "constituencies\n",
            "skyteam\n",
            "north\n",
            "event\n",
            "ryerson\n",
            "proprietary\n",
            "norbert\n",
            "coach\n",
            "choreographer\n",
            "flamenco\n",
            "communist\n",
            "utc03\n",
            "arts\n",
            "japanese\n",
            "motorola\n",
            "springfield\n",
            "relatives\n",
            "monrovia\n",
            "countrycode\n",
            "sang\n",
            "lyrics\n",
            "swiss\n",
            "which\n",
            "unification\n",
            "security\n",
            "birthplace\n",
            "wellfleet\n",
            "coordinated\n",
            "gauck\n",
            "workinstitutions\n",
            "david\n",
            "majestys\n",
            "kola\n",
            "headquarters\n",
            "pavlov\n",
            "directed\n",
            "discoteque\n",
            "products\n",
            "territories\n",
            "derek\n",
            "ballroom\n",
            "castle\n",
            "washington\n",
            "delawares\n",
            "allan\n",
            "cambridgeshire\n",
            "sweden\n",
            "routestart\n",
            "charter\n",
            "kay\n",
            "department\n",
            "operatingsystem\n",
            "grenade\n",
            "yankees\n",
            "carnarvon\n",
            "jack\n",
            "disappeared\n",
            "austin\n",
            "epistle\n",
            "honorificprefix\n",
            "internet\n",
            "secretaryofstate\n",
            "yorkshire\n",
            "karakoram\n",
            "amethyst\n",
            "american\n",
            "peach\n",
            "soundrecording\n",
            "safety\n",
            "list\n",
            "awards\n",
            "dube\n",
            "olaf\n",
            "nearestcity\n",
            "congress\n",
            "gabriel\n",
            "songwriter\n",
            "bill\n",
            "ernst\n",
            "tripartite\n",
            "twelve\n",
            "charles\n",
            "foundationplace\n",
            "movies\n",
            "parliamentary\n",
            "relatedmeanoftransportation\n",
            "shakespeare\n",
            "taiwan\n",
            "acts\n",
            "win\n",
            "famous\n",
            "milonga\n",
            "climate\n",
            "license\n",
            "salaam\n",
            "frank\n",
            ".bt\n",
            "nova\n",
            "1\n",
            "planes.\n",
            "stations\n",
            "northwood\n",
            "samukai\n",
            "producer\n",
            "architecture\n",
            "space\n",
            "lawn\n",
            "catholic\n",
            "congressional\n",
            "mostchamps\n",
            "graa\n",
            "nasa\n",
            "launchsite\n",
            "rhuddlan\n",
            "permanent\n",
            "merit\n",
            "dataset\n",
            "before\n",
            "between\n",
            "jones\n",
            "network\n",
            "zarzuela\n",
            "lowerhouse\n",
            "alice\n",
            "havana\n",
            "nohitter\n",
            "ambassador\n",
            "literature\n",
            "mnster\n",
            "alejandro\n",
            "julie\n",
            "faraday\n",
            "woods\n",
            "brownie\n",
            "vicepresident\n",
            "musicalband\n",
            "others\n",
            "shea\n",
            "newark\n",
            "samantha\n",
            "manfred\n",
            "abjuration\n",
            "tribute\n",
            "italianate\n",
            "james\n",
            "mountain\n",
            "makin\n",
            "stephen\n",
            "flag\n",
            "viejo\n",
            "city\n",
            "coverartist\n",
            "abba\n",
            "currenttraininglocations\n",
            "ordo\n",
            "subgenres\n",
            "kerala\n",
            "woodlawn\n",
            "not\n",
            "cathedral\n",
            "foundedby\n",
            "rafael\n",
            "jeffrey\n",
            "college\n",
            "instruments\n",
            "upperhouse\n",
            "vives\n",
            "g.\n",
            "tamil\n",
            "ireland\n",
            "karma\n",
            "ng\n",
            "leo\n",
            "culture\n",
            "design\n",
            "broadsheet\n",
            "up\n",
            "french\n",
            "frankwalter\n",
            "unrankeddivisio\n",
            "academy\n",
            "sigmar\n",
            "gregory\n",
            "ultraprominent\n",
            "dan\n",
            "call\n",
            "harvard\n",
            "position\n",
            "sequoia\n",
            "optimized\n",
            "nadene\n",
            "greenville\n",
            "workinstitution\n",
            "computers\n",
            "europop\n",
            "gob\n",
            "railway\n",
            "monarch\n",
            "rippon\n",
            "perrysburg\n",
            "patriarch\n",
            "almamater\n",
            "adan\n",
            "kaufman\n",
            "ages\n",
            "tribune\n",
            "spiegel\n",
            "premier\n",
            "monocotyledon\n",
            "sovereigntytype\n",
            "medal\n",
            "australia\n",
            "sampler\n",
            "linnaeus\n",
            "genus\n",
            "northwest\n",
            "aura\n",
            "susan\n",
            "presley\n",
            "chief\n",
            "sa\n",
            "mapungubwe\n",
            "bielecki\n",
            "harald\n",
            "collard\n",
            "youthclubs\n",
            "right\n",
            "lefthand\n",
            "single\n",
            "sworntype\n",
            "guy\n",
            "kemeny\n",
            "arabia\n",
            "anticomintern\n",
            "rupee\n",
            "automobile\n",
            "product\n",
            "llywelyn\n",
            "z3\n",
            "conditioning\n",
            "cctld\n",
            "indonesia\n",
            "mohammad\n",
            "networks\n",
            "connectivity\n",
            "2005\n",
            "tmobile\n",
            "audio\n",
            "writing\n",
            "heine\n",
            "than\n",
            "prekindergarten\n",
            "per\n",
            "scientists\n",
            "york\n",
            "foundedplace\n",
            "use\n",
            "paula\n",
            "duniversitats\n",
            "dartmouth\n",
            "establishedevent\n",
            "storm\n",
            "peace\n",
            "leeds\n",
            "allen\n",
            "l.\n",
            "ministry\n",
            "sacred\n",
            "erna\n",
            "orbit\n",
            "ne\n",
            "number\n",
            "clubs\n",
            "california\n",
            "kawleikgyin\n",
            "system\n",
            "crewson\n",
            "merkel\n",
            "female\n",
            "figure\n",
            "plant\n",
            "sr.\n",
            "by\n",
            "kurtz\n",
            "glen\n",
            "cuba\n",
            "leipzig\n",
            "stateoforigin\n",
            "cree\n",
            "biblepart\n",
            "madison\n",
            "influencedby\n",
            "chris\n",
            "science\n",
            "standard\n",
            "bbc\n",
            "band\n",
            "professional\n",
            "catalonia\n",
            "darwin\n",
            "movement\n",
            "nichols\n",
            "kki\n",
            "tsendhen\n",
            "high\n",
            "rb\n",
            "anders\n",
            "assessment\n",
            "martin\n",
            "dzongkha\n",
            "nationality\n",
            "programmeformat\n",
            "childrens\n",
            "stationtype\n",
            "free\n",
            "noyce\n",
            "recipes\n",
            "ono\n",
            "dvbs\n",
            "rebar\n",
            "latin\n",
            "parent\n",
            "contradanza\n",
            "rcs\n",
            "boulder\n",
            "gigabytes\n",
            "scseat\n",
            "fish\n",
            "southern\n",
            "xarxa\n",
            "settlementtype\n",
            "equipment\n",
            "wireless\n",
            "group\n",
            "marguerite\n",
            "eurodance\n",
            "korakuen\n",
            "crossplatform\n",
            "tim\n",
            "candombe\n",
            "astronauts.\n",
            "come\n",
            "systems\n",
            "america\n",
            "jim\n",
            "enterprise\n",
            "fritz\n",
            "wetterdienst\n",
            "arizona\n",
            "saijo\n",
            "henrys\n",
            "thimphu\n",
            "axis\n",
            "needham\n",
            "charlie\n",
            "bhutanindia\n",
            "good\n",
            "1994\n",
            "ja\n",
            "dance\n",
            "limburgish\n",
            "joss\n",
            "banner\n",
            "nairobi\n",
            "devon\n",
            "greens\n",
            "tundra\n",
            "angeles\n",
            "cook\n",
            "to\n",
            "council\n",
            "formerleagues\n",
            "julian\n",
            "facts\n",
            "tarsus\n",
            "mediatype\n",
            "salamander\n",
            "schrder\n",
            "columbia\n",
            "peanuts\n",
            "organizations\n",
            "yangon\n",
            "laws\n",
            "nor\n",
            "dissolution\n",
            "buzz\n",
            "conservation\n",
            "finns\n",
            "lieutenantgovernor\n",
            "secure\n",
            "beaux\n",
            "relations\n",
            "autoit\n",
            "films\n",
            "dollar\n",
            "claire\n",
            "thicke\n",
            "helmut\n",
            "collective\n",
            "beat\n",
            "bin\n",
            "horizon\n",
            "middle\n",
            "landed\n",
            "largestmetro\n",
            "dwight\n",
            "sempervirens\n",
            "buffaloes\n",
            "u\n",
            "samuel\n",
            "princeton\n",
            "vargas\n",
            "firstascentperson\n",
            "aleut\n",
            "mantis\n",
            "gene\n",
            "jerkins\n",
            "guest\n",
            "johannesburg\n",
            "open\n",
            "papiamento\n",
            ".net\n",
            "skating\n",
            "africa\n",
            "lindsey\n",
            "lawton\n",
            "writer\n",
            "osaka\n",
            "produced\n",
            "w.\n",
            "xinag\n",
            "amor\n",
            "octopetala\n",
            "wolfgang\n",
            "antonia\n",
            "bernard\n",
            "yolande\n",
            "eberhard\n",
            "liberty\n",
            "related\n",
            "nadezda\n",
            "leader\n",
            "mohamed\n",
            "location\n",
            "deborah\n",
            "shag\n",
            "jeddah\n",
            "empire\n",
            "largestcity\n",
            "ted\n",
            "under16\n",
            "financial\n",
            "jacques\n",
            "montague\n",
            "nobel\n",
            "ingrid\n",
            "owner\n",
            "atlarge\n",
            "family\n",
            "memory\n",
            "burlington\n",
            "editor\n",
            "differentfrom\n",
            "russell\n",
            "keypeople\n",
            "harold\n",
            "national\n",
            "boris\n",
            "roger\n",
            "v.\n",
            "this\n",
            "revolutionaries\n",
            "rank\n",
            "elsker\n",
            "braintree\n",
            "microsoft\n",
            "regions\n",
            "first\n",
            "delaware\n",
            "previousoccupation\n",
            "cherryade\n",
            "star\n",
            "senators\n",
            "gauteng\n",
            "edward\n",
            "eyak\n",
            "motomagx\n",
            "lawrence\n",
            "mcleod\n",
            "lipton\n",
            "callingcode\n",
            "physical\n",
            "solberg\n",
            "claudia\n",
            "italy\n",
            "union\n",
            "cumbernauld\n",
            "traffic\n",
            "big\n",
            "wales\n",
            "postalcodetype\n",
            "kohl\n",
            "i\n",
            "placeofbirth\n",
            "inspectorate\n",
            "keyboard\n",
            "influences\n",
            "known\n",
            "ap\n",
            "antonio\n",
            "bride\n",
            "viking\n",
            "athena\n",
            "rosemont\n",
            "norman\n",
            "mitsugu\n",
            "affiliation\n",
            "federal\n",
            "athletics\n",
            "literarygenre\n",
            "plan\n",
            "origin\n",
            "crewmembers\n",
            "rsler\n",
            "hermione\n",
            "1959\n",
            "radical\n",
            "northeast\n",
            "judges\n",
            "christmas\n",
            "monclova\n",
            "motor\n",
            "insect\n",
            "eric\n",
            "mca\n",
            "founder\n",
            "federation\n",
            "pender\n",
            "station\n",
            "law\n",
            "gordon\n",
            "books\n",
            "restingplaceposition\n",
            "year\n",
            "x\n",
            "lugosi\n",
            "scandoromani\n",
            "transaction\n",
            "prodigy.\n",
            "artesia\n",
            "bostrm\n",
            "minister\n",
            "laboratory\n",
            "boiled\n",
            "tagalog\n",
            "executive\n",
            "old\n",
            "musical\n",
            "myanmar\n",
            "at\n",
            "deg\n",
            "dutch\n",
            "software\n",
            "nonaligned\n",
            "nahles\n",
            "runtime\n",
            "11\n",
            "socialist\n",
            "orbitreference\n",
            "paragon\n",
            "att\n",
            "lanka\n",
            "falls\n",
            "programme\n",
            "actor\n",
            "gerhard\n",
            "bicycle\n",
            "community\n",
            "k.\n",
            "e8\n",
            "cycle\n",
            "services\n",
            "blanca\n",
            "tibasic\n",
            "data\n",
            "multilingualism\n",
            "cello\n",
            "elizabeth\n",
            "time\n",
            "boakai\n",
            "kike\n",
            "monty\n",
            "legislature\n",
            "from\n",
            "sons\n",
            "louis\n",
            "political\n",
            "director\n",
            "larsen\n",
            "familia\n",
            "orthodox\n",
            "that\n",
            "embassy\n",
            "laricina\n",
            "mach\n",
            "ten\n",
            "odense\n",
            "electronic\n",
            "emi\n",
            "range\n",
            "mammoth\n",
            "numbers\n",
            "program\n",
            "integer\n",
            "mi6\n",
            "mps\n",
            "drum\n",
            "contra\n",
            "excellency\n",
            "barr\n",
            "thompson\n",
            "fourwheel\n",
            "team\n",
            "sawyer\n",
            "tree\n",
            "leagues\n",
            "crying\n",
            "merrickvillewolford\n",
            "munro\n",
            "locationcountry\n",
            "nevsky\n",
            "elmira\n",
            "lule\n",
            "deputy\n",
            "crime\n",
            "prete\n",
            "texas\n",
            "saudi\n",
            "stockwell\n",
            "philosophy\n",
            "leadername\n",
            "founded\n",
            "gooden\n",
            "grunge\n",
            "tv\n",
            "de\n",
            "behaviorism\n",
            "ingredient\n",
            "asia\n",
            "philipp\n",
            "michael\n",
            "mainclassification\n",
            "greenwich\n",
            "mcmaster\n",
            "bela\n",
            "cory\n",
            "baddeley\n",
            "chipewyan\n",
            "distributor\n",
            "richard\n",
            "anthony\n",
            "colorado\n",
            "yoko\n",
            "launch\n",
            "al\n",
            "target\n",
            "evolutiondata\n",
            "new\n",
            "egypt\n",
            "fire\n",
            "brands\n",
            "winnie\n",
            "yahoo\n",
            "sharks\n",
            "grades\n",
            "fahd\n",
            "joachim\n",
            "rizr\n",
            "mountainrange\n",
            "wallace\n",
            "colonel\n",
            "whig\n",
            "previousmission\n",
            "dougie\n",
            "internal\n",
            "turks\n",
            "ivan\n",
            "formercoach\n",
            "dome\n",
            "lutheranism\n",
            "majorsites\n",
            "song\n",
            "collegeteam\n",
            "rooney\n",
            "binary\n",
            "weapons\n",
            "have\n",
            "khalid\n",
            "resistance\n",
            "township\n",
            "greenhouse\n",
            "sealy\n",
            "tanana\n",
            "been\n",
            "trio.\n",
            "wolf\n",
            "miamidade\n",
            "hamlin\n",
            "blankinfosec\n",
            "vajrayana\n",
            "akerele\n",
            "ethnicgroup\n",
            "pact\n",
            "erie\n",
            "neil\n",
            "nation\n",
            "gatineau\n",
            "processing\n",
            "hawaiialeutian\n",
            ".wales\n",
            "nuclear\n",
            "warren\n",
            "mathematical\n",
            "flaglink\n",
            "women\n",
            "nippon\n",
            "ursula\n",
            "marino\n",
            "layout\n",
            "14\n",
            "does\n",
            "striped\n",
            "most\n",
            "turntable\n",
            "overeaters\n",
            "baguio\n",
            "gruffydd\n",
            "write\n",
            "sweet\n",
            "san\n",
            "10\n",
            "pauline\n",
            "nextmission\n",
            "titleleader\n",
            "colleges\n",
            "voice\n",
            "maxixe\n",
            "allentown\n",
            "saxons\n",
            "seattype\n",
            "famagusta\n",
            "glenda\n",
            "maddux\n",
            "east\n",
            "peak\n",
            "leaders.\n",
            "bulgarian\n",
            "planets\n",
            "truck\n",
            "precededby\n",
            "country\n",
            "klaus\n",
            "pickup\n",
            "online\n",
            "c.\n",
            "we\n",
            "willingham\n",
            "schaumburg\n",
            "on\n",
            "languages\n",
            "award\n",
            "norway\n",
            "makers\n",
            "command\n",
            "starquake\n",
            "monaco\n",
            "khler\n",
            "mase\n",
            "coding\n",
            "popular\n",
            "musiccomposer\n",
            "m.\n",
            "pastparks\n",
            "has\n",
            "counsel\n",
            "players\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gq9KwC8QBOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}